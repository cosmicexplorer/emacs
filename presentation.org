#+TITLE:	Emacs regex compilation
#+SUBTITLE:	future directions for expressive pattern matching
#+AUTHOR:	Danny McClanahan
#+EMAIL:	dmc2@hypnicjerk.ai
#+DATE:		\today

#+DESCRIPTION:
#+KEYWORDS:

#+LANGUAGE: en

#+STARTUP: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [presentation]
#+BEAMER_THEME: Madrid

#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+options: e:t email:nil expand-links:t f:t inline:t num:t p:nil
#+options: pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t
#+options: title:t toc:t todo:t |:t TeX:t LaTeX: t

#+OPTIONS: H:2
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)

#+latex_header: \usepackage{twemojis}
#+latex_header: \AtBeginSection[]{\begin{frame}<beamer>\frametitle{Question}\tableofcontents[currentsection]\end{frame}}

#+latex_footnote_command: \footnote{%s%s}
#+latex_engraved_theme:
#+latex_compiler: pdflatex

* Who are you? Why are you here?
** Answer
*** Who are you?
Danny McClanahan:
- failed an Independent Study in Compiler Design in undergrad attempting to make a C compiler because (as my prof /specifically/ warned me against) I got stuck on the parser.
- spent the next several years realizing that was actually what I should have been doing the whole time.
*** Why are you here?
Because ~emacs-devel~ has taught me so much and I'm about to bowdlerize it all to you!

** ~emacs-devel~
- spent a lot of time learning much of this from ~emacs-devel~
  - was super confused about a lot of dynamics
- thought this would be a matter of just updating the regex engine to use modern techniques
  - turns out the emacs regex engine has features that don't exist in other engines (such as non-contiguous input)
- then thought caching compilation would be enough
  - turns out it's hard to cache
- then i learned about other larger goals for the regex engine which happened to overlap a lot with my own research interests

* What is a regular expression? When and how does implementation match formal theory?
** Answer
*** What is a regular expression?
No one's really sure!
*** When and how does implementation match formal theory?
Formal theory is mostly invoked to post-hoc justify design decisions instead of expanding its expressive power!

** How did this happen?
/This is adapted from "The Four Eras of Regex" by Prof. Jamie Jennings at NCSU: https://jamiejennings.com/posts/2021-09-23-dont-look-back-2./

- regex began as an investigation of formal theories of /parsing/ and /formal languages/
- many features were added on to implementations to improve the practical user experience
  - while the people adding these features were often academics, they were also much more interested in building practical tools
- this led to feature development beyond the range of formal theory (awesome!)
  - however, this also means that functionality becomes *poorly-specified and implementation-defined*
  - formal theory couldn't keep up!

** The 1980s: Moonwalking and Backtracking
/I love Michael Jackson./

- around the 70s-80s-90s, programming languages are trying to get a handle on this whole "text" business
  - (in fact, some programming languages like icon or SNOBOL end up being /entirely/ about text matching)
  - so they began to integrate regex implementations
    - in particular, they start reimplementing vaguely-similar interfaces with vastly different implementations
- 1986: backtracking developed to simulate "egrep-style regular expressions"
  - backtracking ends up being a fantastic way to implement many more features
    - this is really where the break from formal theory begins
  - perl in particular adds a whole host of functionality
    - this locks people into the specifics of perl as a language to perform many text manipulation tasks

** Formal Theory's Response: "You're Holding It Wrong"

- formal theory is (largely still) interested in concrete comparisons of space/runtime
  - much less so in user empowerment
- non-backtracking engines are created (re2, hyperscan, rust regex)
  - these make use of the earlier automaton models with linear runtimes for well-specified search tasks
  - however, they intentionally do not cover anything beyond regular linguistic complexity
    - so what happens if you need to do that?

* What are regexps used for? How do Emacs users use them?
** Answer
*** What are regexps used for?
All variety of text search and parsing tasks!
*** How do Emacs users use them?
As an auxiliary form of logic, to construct the user-level grammar for human thought that Emacs provides: text as input and output.

** Aside: Why is Text Powerful?

- The reason text programming languages are successful is because text is both input (readable) and output (writable).
  - This makes text an extremely empowering and accessible framework to navigate and manipulate program code.
- If there are elements only accessible via a GUI IDE, the developer of the GUI IDE can then exert arbitrary control over your programming output.
  - This kind of dependency is also the goal of statistical models used for text generation such as LLMs, as one among many attempts to subjugate local development to cloud services.
- If you are unable to meaningfully edit parts of the code without interacting with a black-box external system, then you have a hidden dependency.
  - If you cannot reproduce a system /locally/, it becomes a black-box external system.
  - *Text is local.*

** Emacs \twemoji{two_hearts} Text

- Emacs is a text editor which implements much of its own logic and user interface via text.
  - This is why we have elisp, a language tightly integrated with text operations from the editor.
- Because text forms UI, /parsing/ and /text search/ can be employed not just to edit code, but to construct a user interface from text input.
  - This means that language-level mechanisms for text such as the regex engine can be extended into the user interface.

** Who Says Text is Empowering?
Not everyone thinks text is empowering! Formal theory thinks nobody should be allowed to parse text without their tools!

*** "Don't parse HTML with regex"
"Everyone knows" not to parse HTML with regex, because regex (alone!!!) aren't sufficiently powerful to parse HTML:
- But nobody is parsing HTML with a single massive regex!
- Regex + mutable state can achieve arbitrary linguistic complexity very easily!
- And regex search for a specific substring is much faster than parsing everything up front!

** Emacs Says So!
This isn't remotely a concern for Emacs code, which regularly uses regexps to parse HTML and other programming languages! How?

- text properties
  - used to write state to the text which is used in conjunction with regex to achieve greater linguistic complexity
- syntax parsing
  - regex engine is aware of this via syntax classes
- jit-lock-mode
  - use smart heuristics to only reparse what's been modified

** But....
There /are/ actually reasons to avoid this!

- Regexps may have extremely non-obvious dependencies on parse context.
  - A non-greedy match may be correct when invoked in a restricted context, but may become subtly incorrect when used more generally.
  - For example, ~(\_<.*?):~ could match a symbol before a ~:~ (like ~a:~ in JavaScript), but could unintentionally match string properties like ~"a:b":~ as ~a:~ too!
- While text properties and buffer-local variables can retain the state necessary to parse non-regular languages, coordinating that state can be error-prone.
  - Since *there are no existing formalisms to link regex with external state*, it can become extremely difficult to reproduce the precise internal state which generates a logic bug in an elisp mode.

** ~tree-sitter~

In fact, ~tree-sitter~ (since Emacs 29) was created to solve this problem /for well-specified language definitions/.

- It is a highly constraining formal tool!
- And it means you now depend on:
  - The tree-sitter grammar for your language (which is obnoxious to read and write).
  - The ~tree-sitter~ library (which does not have universal uptake within distros).

So I don't like it! But for the specific task of parsing a programming language, it happens to solve a lot of other problems at once.

** So Why Use Regex?
So why are we talking about regex here? Mainly:
- parsing programming languages is a very small subset of all text search/matching tasks!
- regex can be directly manipulated by the user!

For the interactive experiences that Emacs excels at, regex provides a powerful language /for both input and output/:
- it can be synthesized hygienically from elisp code via ~rx~, either statically at load time or dynamically at run time!
- it can be received or transformed from user input to specify powerful queries over complex data!
  - *see ~helm-rg~, ~telepathygrams~ at end*

...but this might require going beyond "regex" alone!

* What is the emacs regex engine? How is it invoked?
** Answer
This section is an unfortunately brief walkthrough through the current regex engine logic:

*** What is the emacs regex engine?
It's a backtracking engine over multibyte codepoints, defined in ~src/regex-emacs.c~.
*** How is it invoked?
In two ways:
- over a single contiguous string input,
- over the two halves of the gap buffer.

** ~regex-emacs~
- the compiled pattern is stored as an ~re_pattern_buffer~ struct from ~src/regex-emacs.h~
- matching loop in ~re_match_2_internal()~ in ~src/regex-emacs.c~:
  - extract current and next char
    - perform multibyte varint decoding to iterate bytes
    - translate input characters via the case-folding char-table
  - read instruction from instruction pointer
  - big switch statement for the next instruction from the compiled pattern
    - if instruction uses syntax, read the syntax class for the current character from the current syntax table
  - increment both pointers as well as the instruction pointer (if instruction was not a jump)
  - if we've concluded a capture, write the end position to the C-level array ~re_nsub~
- non-contiguous matching over the two halves of the gap buffer is supported by checking at each point whether we have progressed to the end of the first half, and then switching over to the second half
  - this allows the same code to be used for single-string search, as it simply avoids checking a NULL second pointer and only checks if we've reached the end of the first input

** Multibyte
- It turns out this actually isn't terribly relevant to the regex engine!
  - Or at least, it doesn't really differ from "standard" Unicode regex matching.
  - /There is no standard: https://jamiejennings.com/posts/2021-09-07-dont-look-back-1./
- Emacs reads in data from whatever encoding into multibyte, and the regex engine only acts upon this normalized encoding.
  - https://www.gnu.org/software/emacs/manual/html_node/elisp/Text-Representations.html

* How could we do regex better in Emacs? How could Emacs do regex better than anywhere else?
** Answer
This section will describe several potential paths we might investigate, paraphrasing discussion from ~emacs-devel~:

*** How could we do regex better in Emacs?
- introspection
- optimization
*** How could Emacs do regex better than anywhere else?
- explicit control over linguistic complexity
- libraries of composeable patterns

** Separately-Compiled Regexps
*Precompile regexps to enable more powerful compilation techniques.*

- have demonstrated this in a test branch: https://github.com/cosmicexplorer/emacs/tree/lisp-level-regex
- artificial benchmarks show an improvement, but haven't been able to produce apples-to-apples comparison yet
- syntax highlighting would be the most appropriate, but caching these compiles currently makes syntax parsing fail

** Match Over Bytes, not Chars
*Compile patterns to byte-level automata, then iterate over bytes.*

- char-by-char varint decoding of multibyte/utf8 is comparatively slow
  - this is the reason go's "re2" is much much slower than the c++ re2 library
- we can do this work at compile time instead, generating a larger automaton in order to be able to think in terms of byte ranges instead
  - this is already what we do for e.g. char-folding
  - this is a necessary prerequisite for SIMD instructions

** Expose SIMD literal search
*Expose a SIMD literal search method for specific search tasks.*

- this is used as a "prefilter" optimization in high-performance regex engines
  - https://github.com/BurntSushi/rebar
- this is one of the most significant contributions to performance in these engines, skipping over much of the input before executing the byte-by-byte automaton

** Explicit Control over Linguistic Complexity
*Expose APIs which enforce a strict degree of linguistic complexity for deterministic runtime.*

- searching for a literal string tends to be a special case, and the user should be able to make absolutely sure Emacs uses the faster algorithm, or error out if the input was invalid
  - searching for a set of literals (e.g. keywords) at once can also be done very efficiently with specific algorithms that don't use a general NFA
- we already duck out to a special literal matching engine in ~search.c~ if we're matching a literal against a buffer, but this requires a heuristic check for literal-only strings instead of enforcing them, resulting in difficult-to-understand performance characteristics
  - this also involves an entirely separate code path
- backrefs are a special case on the other end of complexity
  - recently formalized: https://jamiejennings.com/posts/2023-10-01-dont-look-back-3/

** Lisp Regexp Library
*Expose a Lisp-level library for regexp matching.*

- the compiled form of the regexp in ~re_pattern_buffer~ can be /executed/, but not really /introspected/
  - no form of "IR": this also contributes to the difficulty of composing patterns together
  - this is largely because it's implemented in C
- we have libgccjit now: why not implement the regex engine itself in lisp???
  - proposal from Pip Cet (CHECK!) on ~emacs-devel~
  - biggest issue for optimization: lisp code (or native modules) can't access or operate on the separate halves of the gap buffer

- Emacs could implement this via elisp macros, or with new elisp constructs.
  - New elisp constructs means C code or some other dependency.
  - Integration into ~pcase~ could achieve a form of type safety along with interleaving lisp-level matching logic.

* Current and Future Work
** ~helm-rg~
- https://github.com/cosmicexplorer/helm-rg
- show screenshot
- mention how ~"a b"~ generates ~"a.*b|b.*a"~

** Libraries of Composeable Patterns
*Define a "bidirectional" semantics for parse/search control flow across subgrammars:*
- *so patterns can be tested and reused.*
- *so parsing and searching can be performed in parallel, or distributed across time and space.*

** Barriers to Composition
~rx~ is a really fantastic precedent for hygienically composing regexps alone!
- But (I claim that) parsers for regular languages cannot be used as a "black box" component of a more complex parsing operation.
- More seriously, executing a regex currently requires always reading the entire input from left to right.
  - For example, you can't match a regex on the left side and then one on the right, and then merge their results into a single parse state.
- This is /also/ true for parsers of more-complex languages!

*This means that every single parsing task always has a strict data dependency on the next byte of input,* which /drastically/ limits the ability to optimize!
- Instead of matching against numeric offsets, we end up matching against contextual pointers!
- The parse state needs to be more /formalized/ so that it may be /virtualized/ and thereby /optimized/.

** Virtualizing Parse State

~telepathygrams~: https://github.com/cosmicexplorer/telepathygrams
- i'm working on a code search tool that precompiles a database to execute NFAs against
  - basically etags but an n-gram index instead of a symbol index
  - this is because I want to "beat ripgrep by cheating" with a precompiled index
- n-gram indices have been done (e.g. Kythe), but I don't want to just find where to start my search--I want to execute the entire search against the index!
  - This requires virtualizing the state of an NFA so that it may be executed against a multi-level index, in parallel, across machines.
- This may fail, but it will be fun!

** End
Hoping to work on lots of stuff around these subjects for a doctoral degree!

*** text
- mastodon: [[https://circumstances.run/@hipsterelectron][~@hipsterelectron@circumstances.run~]]
  - /also twitter, bluesky/

*** code
- codeberg: [[https://codeberg.org/cosmicexplorer][~@cosmicexplorer~]]
  - github: [[https://github.com/cosmicexplorer][~@cosmicexplorer~]]
