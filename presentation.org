#+TITLE:	Emacs regex compilation
#+SUBTITLE:	future directions for expressive pattern matching
#+AUTHOR:	Danny McClanahan
#+EMAIL:	dmc2@hypnicjerk.ai
#+DATE:		\today

#+DESCRIPTION:
#+KEYWORDS:

#+LANGUAGE: en

#+STARTUP: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [presentation]
#+BEAMER_THEME: Madrid

#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+options: e:t email:nil expand-links:t f:t inline:t num:t p:nil
#+options: pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t
#+options: title:t toc:t todo:t |:t TeX:t LaTeX: t

#+OPTIONS: H:2
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)

#+latex_header: \AtBeginSection[]{\begin{frame}<beamer>\frametitle{Question}\tableofcontents[currentsection]\end{frame}}

#+latex_footnote_command: \footnote{%s%s}
#+latex_engraved_theme:
#+latex_compiler: pdflatex

* What is a regular expression? When and how does implementation match formal theory?
** Answer
*** What is a regular expression?
No one's really sure!
*** When and how does implementation match formal theory?
Formal theory is mostly invoked to post-hoc justify design decisions instead of expanding its expressive power!

** How did this happen?
(This is adapted from [[https://jamiejennings.com/posts/2021-09-23-dont-look-back-2/]["The Four Eras of Regex"]] by Prof. Jamie Jennings at NCSU.)

- regex began as an investigation of formal theories of /parsing/ and /formal languages/
- many features were added on to implementations to improve the practical user experience
  - while the people adding these features were often academics, they were also much more interested in building practical tools
- this led to feature development beyond the range of formal theory (awesome!)
  - however, this also means that functionality becomes *poorly-specified and implementation-defined*
  - formal theory couldn't keep up!

** The 1980s: Moonwalking and Backtracking

- around the 70s-80s-90s, programming languages are trying to get a handle on this whole "text" business
  - (in fact, some programming languages like icon or SNOBOL end up being /entirely/ about text matching)
  - so they began to integrate regex implementations
    - in particular, they start reimplementing vaguely-similar interfaces with vastly different implementations
- 1986: backtracking developed to simulate "egrep-style regular expressions"
  - backtracking ends up being a fantastic way to implement many more features
    - this is really where the break from formal theory begins
  - perl in particular adds a whole host of functionality
    - this locks people into the specifics of perl as a language to perform many text manipulation tasks

** Formal Theory's Response: "You're Holding It Wrong"

- formal theory is (largely still) interested in concrete comparisons of space/runtime
  - much less so in user empowerment
- non-backtracking engines are created (re2, hyperscan, rust regex)
  - these make use of the earlier automaton models with linear runtimes for well-specified search tasks
  - however, they intentionally do not cover anything beyond regular linguistic complexity
    - so what happens if you need to do that?

** Parsing Theory has Become Extremely Inflexible

- people just don't use formalisms, because they don't cover their use case!
  - this is a HUGE problem: the point where the computer interfaces with the outside world is exactly the place where programmers DON'T and CAN'T make use of formal theory!
- because regex are built-in to the programming language, people use them instead
  - in addition to being poorly-specified and implementation-defined, they're now also overloaded with text manipulation tasks beyond their capabilities!
- for specific formal reasons, *regex cannot be composed together* like productions in a CFG
  - linear automata cannot be started in one place and resumed in another
    - a regex engine can't run two threads in parallel and "meet in the middle"

* What are regexps used for? How do Emacs users use them?
** Answer
*** What are regexps used for?
All variety of text search and parsing tasks!
*** How do Emacs users use them?
As an auxiliary form of logic, to construct the user-level grammar for human thought that Emacs provides: text as input and output.

** a
*** "Don't parse HTML with regex"
regex + mutable state can achieve arbitrary linguistic complexity very easily

*** C Lexer Hack
this is basically why bison and friends aren't used for so many production languages!

** b
Emacs is a delightful case study for the capabilities of regular expressions, because Emacs forms user interfaces via text, which retains the expressivity of a GUI with the user-level interactivity of written language. Because we use text for both input and output, regexps in Emacs form part of a user-level grammar for human thought. As a result, Emacs and Emacs users have a rich intuitive grasp of regular expressions, which provides a unique vantage point to consider how they may be improved in general.
** d
text properties, syntax parsing, buffer-local variables, jit-lock-mode
*** huh
emacs text properties and buffer-local variables provide mutable state for regex search to interact with
*** ah
this can become very difficult to reproduce the precise internal state which leads to e.g. a logic bug in elisp code

* What does Emacs require from a regex engine? How does that differ from other engines?
When I began my investigation, I assumed that Emacs would be able to use an existing off-the-shelf regex engine, that this would be more performant than regex-emacs.c, and that the greatest challenge would be providing a sufficiently robust build process (see emacs-devel: https://lists.gnu.org/archive/html/emacs-devel/2024-04/msg00142.html). However, I quickly found that Emacs (as usual) is far more configurable than alternatives (see rust regex discussion: https://github.com/rust-lang/regex/discussions/1167#discussioncomment-8585027). Now don't get this twisted: emacs-devel was open to deprecating functionality that hampered optimization! But the biggest challenge by far is that regex-emacs.c is categorically more powerful than alternatives: it can match against non-contiguous input (across both halves of the gap buffer), as well as non-UTF8 text with its fantastic multibyte encoding (see https://www.gnu.org/software/emacs/manual/html_node/elisp/Text-Representations.html).

# this needs to be about:
# (1) what i *thought* needed to be changed
# (2) the obstacles to doing so
# (3) the greater discussion from emacs-devel
# (4) ways we can investigate

** What is the input to the regex engine? When and how does the multibyte encoding come into play?
So a more complex picture begins to emerge: Emacs actually uses regexps far more widely and deeply than anywhere else, and its regex engine requirements aren't "legacy", but the result of caring more deeply about language than anywhere else. While regex engines have historically been known to introduce functionality not backed by formal theory that's later found to be hard to optimize, Emacs instead charts a path for other engines to follow. Formalizing backrefs is state-of-the-art, but possible (see https://jamiejennings.com/posts/2021-09-23-dont-look-back-2/), and I believe the same can be achieved for the other affordances Emacs users have come to expect. Subsequently, I have focused on identifying where we can constrain the problem space to improve performance without losing those affordances, such as explicit precompilation in lisp code (see https://lists.gnu.org/archive/html/emacs-devel/2024-08/msg00108.html).

** How do regex-emacs.c and search.c invoke the regex engine from lisp code?
ok3

* Future Directions: Introspection, Composability, and Optimization
** ~emacs-devel~
~emacs-devel~ noted several places where the regex engine was causing problems, and proposed separate solutions for each

** introspection

** composability

** optimization

** d
There are many branching paths here. With the libgccjit native compiler, we can now implement regex matching in lisp itself. While `rx' can compose patterns to an extent, we could provide a more powerful primitive than regular expressions alone for complex parsing tasks. And while many regex engines employ complex optimization heuristics, we can instead introduce specific functionality for e.g. SIMD literal search into lisp code, allowing lisp users to intelligently select for themselves how and when to employ less-powerful but more-performant search routines.

We don't need to backtrack! We can try all these paths at once.
